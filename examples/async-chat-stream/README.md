# async-chat-stream

This example demonstrates how to create a conversation history using an asynchronous Ollama client and the chat endpoint. The streaming response is outputted to `stdout` as well as a TTS if enabled with `--speak` and available. Supported TTS are `say` on macOS and `espeak` on Linux.

----


# 异步聊天流示例

此示例展示了如何使用异步Ollama客户端和聊天端点创建对话历史。流式响应将输出至标准输出（`stdout`），并且在启用了`--speak`选项且可用的情况下，还会通过文本转语音（TTS）播放。支持的TTS包括macOS上的`say`和Linux上的`espeak`。
